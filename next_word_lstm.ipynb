{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description : Next WOrd Prediction Using LSTM\n",
    "### Project Description\n",
    "\n",
    "This project aims to develop a deep learning model for predicting the next word in a given sequence of words.\n",
    "The model is built using LSTM network, which are well-suited for sequence prediction tasks. THe project include  the following steps:\n",
    "\n",
    "1.  Data Collection\n",
    "    we use the text of shakespear's \"Hamlet\" as out dataset .The rich, Complex text provides a good challenge for our model.\n",
    "\n",
    "2. Data Preprocessing : The text data is tokenized, Converted into sequence, and padded to ensure uniform input lengths. THe sequence are then split into training and testing sets.\n",
    "\n",
    "3. Model Building : An LSTM model is constructed with an embedding layer, two LSTM layers and a dense output layer with a softmax activation function to predict the probability of the next word.\n",
    "\n",
    "4. Model Training : The model is trained using the prepared sequence, with early stopping implemented to prevent overfitting. Early stopping monitors the  validation loss and stops training when the loss stops improving.\n",
    "\n",
    "5. Model Evaluation : The Mmodel is evaluated using a set of example sentences to test its ability to predict the next word accurately.\n",
    "\n",
    "6. Deployment : A streamlit web application is developed to allow users to input a sequence of words and get the predicted next word in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Collection\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "## Save to a file \n",
    "with open('hamlet.txt','w') as file :\n",
    "    file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the dataset\n",
    "\n",
    "with open('hamlet.txt','r') as file :\n",
    "    text = file.read().lower()\n",
    "\n",
    "## Tokenize the text-creating indexes for words\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (617353399.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    for line in text.split('\\n'):\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Create Input Sequences\n",
    "input_sequence = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequence.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
